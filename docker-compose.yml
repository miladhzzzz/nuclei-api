services:
  nuclei-api:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8080"
    volumes:
      - ${DOCKER_SOCK_PATH:-/var/run/docker.sock}:/var/run/docker.sock
      - ./nuclei-templates:/root/nuclei-templates
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
    privileged: true
    restart: unless-stopped

  redis:
    image: redis:6
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
    ports: 
       - "6379:6379"
    restart: unless-stopped

  celery_worker:
    build: .
    command: celery -A celery_config:celery_app worker --loglevel=info --concurrency=1
    privileged: true
    depends_on:
      - redis
    deploy:
      mode: replicated
      replicas: 1
    volumes:
      - ./nuclei-templates/ai:/app/templates
      - ${DOCKER_SOCK_PATH:-/var/run/docker.sock}:/var/run/docker.sock
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
    restart: unless-stopped
    
  celery_beat:
    build: .
    command: celery -A celery_config:celery_app beat --loglevel=info
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
    depends_on:
      - redis
    restart: unless-stopped

  flower:
    image: mher/flower
    command: celery --broker=redis://redis:6379/0 flower --port=5555
    ports:
      - "5555:5555"
    environment:
      - FLOWER_UNAUTHENTICATED_API=true
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
    depends_on:
      - redis
      - celery_worker
    restart: unless-stopped

  ollama:
    image: ollama/ollama
    ports: 
       - "11434:11434"  # Ollama API port
    volumes:
      - ollama-data:/root/.ollama  # Persist models
      - /etc/localtime:/etc/localtime:ro
      - ./etc/entrypoint.sh:/entrypoint.sh
    environment:
      # Choose ONE of the two styles below

      # ── Style A: single model (simplest)
      MODEL: "deepseek-coder:1.3b"

      # ── Style B: multiple models (more flexible)
      # MODELS: "deepseek-coder:1.3b llama3.2:3b nomic-embed-text:latest"

      # Optional AMD GPU override (uncomment if needed)
      # HSA_OVERRIDE_GFX_VERSION: "8.0.3"
    entrypoint: ["/usr/bin/sh", "/entrypoint.sh"]
    restart: unless-stopped

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    ports:
      - "3331:8080"  # Open WebUI runs on 8080 internally, mapped to 3000
    volumes:
      - open-webui-data:/app/backend/data  # Persist Open WebUI data
    environment:
      - OLLAMA_API_BASE_URL=http://ollama:11434  # Connect to Ollama
    depends_on:
      - ollama

  nuclei-fingerprint:
    build:
      context: ./fingerprint-service
      dockerfile: Dockerfile
    depends_on: []
      # - nuclei-api
    ports: 
       - "3330:3000"
    restart: unless-stopped

  loki:
      image: grafana/loki:3.4.2
      ports:
        - "3100:3100"
      restart: unless-stopped
      command: -config.file=/etc/loki/loki.yml
      volumes:
        - loki_data:/tmp/loki
        - ./loki:/etc/loki
        - /etc/localtime:/etc/localtime:ro
        - /etc/timezone:/etc/timezone:ro

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    restart: unless-stopped
    depends_on:
      - prometheus

  # nuclei-ui:
  #   build:
  #     context: ./ui
  #     dockerfile: Dockerfile
  #   depends_on:
  #     - nuclei-api
  #   ports:
  #     - "3000:80"
  #   restart: unless-stopped

volumes:
  ollama-data:
  open-webui-data:
  loki_data:
  prometheus_data:
  grafana_data:
