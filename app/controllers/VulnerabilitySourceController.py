import json
import requests
import asyncio
import aiohttp
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
import logging
from bs4 import BeautifulSoup
import re
from urllib.parse import quote_plus
import time

logger = logging.getLogger(__name__)

class VulnerabilitySourceController:
    def __init__(self, sources_file: str = "data/vulnerability_sources.json"):
        self.sources_file = sources_file
        self.sources_config = self._load_sources_config()
        self.cache = {}
        self.cache_duration = self.sources_config.get("cache_duration", 3600)
        self.test_mode = self.sources_config.get("test_mode", False)
        
    def _load_sources_config(self) -> Dict:
        """Load vulnerability sources configuration from JSON file"""
        try:
            with open(self.sources_file, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.error(f"Sources configuration file not found: {self.sources_file}")
            return {"sources": [], "search_strategies": {}, "test_mode": False}
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in sources configuration: {e}")
            return {"sources": [], "search_strategies": {}, "test_mode": False}
    
    def update_sources_config(self, new_config: Dict) -> bool:
        """Update the sources configuration file"""
        try:
            with open(self.sources_file, 'w') as f:
                json.dump(new_config, f, indent=2)
            self.sources_config = new_config
            self.test_mode = new_config.get("test_mode", False)
            return True
        except Exception as e:
            logger.error(f"Failed to update sources configuration: {e}")
            return False
    
    def get_enabled_sources(self) -> List[Dict]:
        """Get list of enabled vulnerability sources"""
        return [source for source in self.sources_config.get("sources", []) 
                if source.get("enabled", False)]
    
    async def fetch_vulnerabilities(self, query: str, max_results: int = 50) -> Dict[str, Any]:
        """Fetch vulnerabilities from all enabled sources"""
        # If in test mode, return only 1 CVE from NVD
        if self.test_mode:
            logger.info("Test mode enabled - returning single CVE from NVD")
            return await self._fetch_test_vulnerability(query)
        
        enabled_sources = self.get_enabled_sources()
        results = {
            "query": query,
            "timestamp": datetime.now().isoformat(),
            "sources_queried": len(enabled_sources),
            "results": [],
            "summary": {
                "total_vulnerabilities": 0,
                "unique_cves": set(),
                "source_breakdown": {}
            }
        }
        
        # Create tasks for all sources
        tasks = []
        for source in enabled_sources:
            task = self._fetch_from_source(source, query, max_results)
            tasks.append(task)
        
        # Execute all tasks concurrently
        source_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Process results
        for i, result in enumerate(source_results):
            source_name = enabled_sources[i]["name"]
            if isinstance(result, Exception):
                logger.error(f"Error fetching from {source_name}: {result}")
                results["summary"]["source_breakdown"][source_name] = {
                    "status": "error",
                    "count": 0,
                    "error": str(result)
                }
            else:
                results["results"].extend(result.get("vulnerabilities", []))
                results["summary"]["source_breakdown"][source_name] = {
                    "status": "success",
                    "count": len(result.get("vulnerabilities", [])),
                    "response_time": result.get("response_time", 0)
                }
        
        # Update summary
        results["summary"]["total_vulnerabilities"] = len(results["results"])
        results["summary"]["unique_cves"] = len(set(
            vuln.get("cve_id") for vuln in results["results"] 
            if vuln.get("cve_id")
        ))
        
        return results
    
    async def _fetch_test_vulnerability(self, query: str) -> Dict[str, Any]:
        """Fetch a single test vulnerability from NVD"""
        try:
            url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
            params = {
                "keywordSearch": query,
                "resultsPerPage": 1
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        vulnerabilities = []
                        
                        for vuln in data.get("vulnerabilities", []):
                            cve = vuln.get("cve", {})
                            vulnerabilities.append({
                                "cve_id": cve.get("id"),
                                "description": cve.get("descriptions", [{}])[0].get("value", ""),
                                "severity": cve.get("metrics", {}).get("cvssMetricV31", [{}])[0].get("cvssData", {}).get("baseSeverity"),
                                "score": cve.get("metrics", {}).get("cvssMetricV31", [{}])[0].get("cvssData", {}).get("baseScore"),
                                "published_date": cve.get("published"),
                                "source": "NVD",
                                "url": f"https://nvd.nist.gov/vuln/detail/{cve.get('id')}"
                            })
                        
                        return {
                            "query": query,
                            "timestamp": datetime.now().isoformat(),
                            "test_mode": True,
                            "sources_queried": 1,
                            "results": vulnerabilities,
                            "summary": {
                                "total_vulnerabilities": len(vulnerabilities),
                                "unique_cves": len(vulnerabilities),
                                "source_breakdown": {
                                    "NVD": {
                                        "status": "success",
                                        "count": len(vulnerabilities),
                                        "response_time": 0
                                    }
                                }
                            }
                        }
                    else:
                        return {
                            "query": query,
                            "timestamp": datetime.now().isoformat(),
                            "test_mode": True,
                            "error": f"NVD API returned status {response.status}",
                            "results": [],
                            "summary": {
                                "total_vulnerabilities": 0,
                                "unique_cves": 0,
                                "source_breakdown": {}
                            }
                        }
        except Exception as e:
            logger.error(f"Error fetching test vulnerability: {e}")
            return {
                "query": query,
                "timestamp": datetime.now().isoformat(),
                "test_mode": True,
                "error": str(e),
                "results": [],
                "summary": {
                    "total_vulnerabilities": 0,
                    "unique_cves": 0,
                    "source_breakdown": {}
                }
            }
    
    async def _fetch_from_source(self, source: Dict, query: str, max_results: int) -> Dict:
        """Fetch vulnerabilities from a specific source"""
        start_time = time.time()
        source_name = source["name"]
        source_type = source.get("type", "api")
        
        try:
            if source_type == "api":
                result = await self._fetch_from_api(source, query, max_results)
            elif source_type == "web_scraper":
                result = await self._fetch_from_web_scraper(source, query, max_results)
            else:
                raise ValueError(f"Unknown source type: {source_type}")
            
            result["response_time"] = time.time() - start_time
            return result
            
        except Exception as e:
            logger.error(f"Error fetching from {source_name}: {e}")
            raise
    
    async def _fetch_from_api(self, source: Dict, query: str, max_results: int) -> Dict:
        """Fetch vulnerabilities from API-based sources"""
        source_name = source["name"]
        endpoints = source.get("endpoints", {})
        
        async with aiohttp.ClientSession() as session:
            if source_name == "NVD":
                return await self._fetch_from_nvd(session, query, max_results)
            elif source_name == "CVE-MITRE":
                return await self._fetch_from_cve_mitre(session, query, max_results)
            elif source_name == "ExploitDB":
                return await self._fetch_from_exploitdb(session, query, max_results)
            elif source_name == "Vulners":
                return await self._fetch_from_vulners(session, query, max_results)
            elif source_name == "GitHub-Advisories":
                return await self._fetch_from_github_advisories(session, query, max_results)
            elif source_name == "OSV":
                return await self._fetch_from_osv(session, query, max_results)
            else:
                # Generic API fetch
                return await self._fetch_generic_api(session, source, query, max_results)
    
    async def _fetch_from_nvd(self, session: aiohttp.ClientSession, query: str, max_results: int) -> Dict:
        """Fetch from NVD API"""
        url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
        params = {
            "keywordSearch": query,
            "resultsPerPage": min(max_results, 20)
        }
        
        async with session.get(url, params=params) as response:
            if response.status == 200:
                data = await response.json()
                vulnerabilities = []
                
                for vuln in data.get("vulnerabilities", []):
                    cve = vuln.get("cve", {})
                    vulnerabilities.append({
                        "cve_id": cve.get("id"),
                        "description": cve.get("descriptions", [{}])[0].get("value", ""),
                        "severity": cve.get("metrics", {}).get("cvssMetricV31", [{}])[0].get("cvssData", {}).get("baseSeverity"),
                        "score": cve.get("metrics", {}).get("cvssMetricV31", [{}])[0].get("cvssData", {}).get("baseScore"),
                        "published_date": cve.get("published"),
                        "source": "NVD",
                        "url": f"https://nvd.nist.gov/vuln/detail/{cve.get('id')}"
                    })
                
                return {"vulnerabilities": vulnerabilities}
            else:
                raise Exception(f"NVD API returned status {response.status}")
    
    async def _fetch_from_cve_mitre(self, session: aiohttp.ClientSession, query: str, max_results: int) -> Dict:
        """Fetch from CVE MITRE via CIRCL API"""
        url = f"https://cve.circl.lu/api/cve/{quote_plus(query)}"
        
        async with session.get(url) as response:
            if response.status == 200:
                data = await response.json()
                vulnerabilities = []
                
                if isinstance(data, dict):
                    vulnerabilities.append({
                        "cve_id": data.get("id"),
                        "description": data.get("summary", ""),
                        "severity": data.get("cvss", ""),
                        "published_date": data.get("Published"),
                        "source": "CVE-MITRE",
                        "url": f"https://cve.mitre.org/cgi-bin/cvename.cgi?name={data.get('id')}"
                    })
                
                return {"vulnerabilities": vulnerabilities}
            else:
                raise Exception(f"CVE MITRE API returned status {response.status}")
    
    async def _fetch_from_exploitdb(self, session: aiohttp.ClientSession, query: str, max_results: int) -> Dict:
        """Fetch from ExploitDB"""
        url = "https://www.exploit-db.com/search"
        params = {"q": query}
        
        async with session.get(url, params=params) as response:
            if response.status == 200:
                html = await response.text()
                return await self._parse_exploitdb_html(html, max_results)
            else:
                raise Exception(f"ExploitDB returned status {response.status}")
    
    async def _parse_exploitdb_html(self, html: str, max_results: int) -> Dict:
        """Parse ExploitDB HTML response"""
        soup = BeautifulSoup(html, 'html.parser')
        vulnerabilities = []
        
        # Find exploit entries (this is a simplified parser)
        exploit_entries = soup.find_all('tr', class_='exploit')
        
        for entry in exploit_entries[:max_results]:
            try:
                title_elem = entry.find('td', class_='description')
                if title_elem:
                    title = title_elem.get_text(strip=True)
                    link = title_elem.find('a')
                    url = f"https://www.exploit-db.com{link['href']}" if link else ""
                    
                    vulnerabilities.append({
                        "cve_id": None,  # ExploitDB doesn't always have CVE IDs
                        "description": title,
                        "severity": "unknown",
                        "source": "ExploitDB",
                        "url": url
                    })
            except Exception as e:
                logger.warning(f"Error parsing ExploitDB entry: {e}")
        
        return {"vulnerabilities": vulnerabilities}
    
    async def _fetch_from_vulners(self, session: aiohttp.ClientSession, query: str, max_results: int) -> Dict:
        """Fetch from Vulners API"""
        url = "https://vulners.com/api/v3/search/exploit/"
        data = {
            "query": query,
            "size": max_results
        }
        
        async with session.post(url, json=data) as response:
            if response.status == 200:
                data = await response.json()
                vulnerabilities = []
                
                for vuln in data.get("data", {}).get("search", []):
                    vulnerabilities.append({
                        "cve_id": vuln.get("cvelist", [None])[0] if vuln.get("cvelist") else None,
                        "description": vuln.get("description", ""),
                        "severity": vuln.get("cvss", {}).get("score"),
                        "source": "Vulners",
                        "url": vuln.get("href", "")
                    })
                
                return {"vulnerabilities": vulnerabilities}
            else:
                raise Exception(f"Vulners API returned status {response.status}")
    
    async def _fetch_from_github_advisories(self, session: aiohttp.ClientSession, query: str, max_results: int) -> Dict:
        """Fetch from GitHub Security Advisories"""
        url = "https://api.github.com/advisories"
        params = {"query": query}
        
        async with session.get(url, params=params) as response:
            if response.status == 200:
                data = await response.json()
                vulnerabilities = []
                
                for advisory in data.get("data", {}).get("securityAdvisories", {}).get("nodes", [])[:max_results]:
                    vulnerabilities.append({
                        "cve_id": advisory.get("identifiers", [{}])[0].get("value"),
                        "description": advisory.get("summary", ""),
                        "severity": advisory.get("severity"),
                        "published_date": advisory.get("publishedAt"),
                        "source": "GitHub-Advisories",
                        "url": advisory.get("permalink", "")
                    })
                
                return {"vulnerabilities": vulnerabilities}
            else:
                raise Exception(f"GitHub Advisories API returned status {response.status}")
    
    async def _fetch_from_osv(self, session: aiohttp.ClientSession, query: str, max_results: int) -> Dict:
        """Fetch from OSV API"""
        url = "https://api.osv.dev/v1/query"
        data = {
            "q": query,
            "limit": max_results
        }
        
        async with session.post(url, json=data) as response:
            if response.status == 200:
                data = await response.json()
                vulnerabilities = []
                
                for vuln in data.get("vulns", []):
                    vulnerabilities.append({
                        "cve_id": vuln.get("aliases", [None])[0] if vuln.get("aliases") else None,
                        "description": vuln.get("summary", ""),
                        "severity": vuln.get("severity", [{}])[0].get("type") if vuln.get("severity") else None,
                        "published_date": vuln.get("published"),
                        "source": "OSV",
                        "url": f"https://ossf.github.io/osv-schema/#{vuln.get('id')}"
                    })
                
                return {"vulnerabilities": vulnerabilities}
            else:
                raise Exception(f"OSV API returned status {response.status}")
    
    async def _fetch_generic_api(self, session: aiohttp.ClientSession, source: Dict, query: str, max_results: int) -> Dict:
        """Generic API fetch for unknown sources"""
        endpoints = source.get("endpoints", {})
        if not endpoints:
            return {"vulnerabilities": []}
        
        # Try the first available endpoint
        endpoint_url = list(endpoints.values())[0]
        
        async with session.get(endpoint_url, params={"q": query, "limit": max_results}) as response:
            if response.status == 200:
                data = await response.json()
                # Generic parsing - this would need to be customized per source
                return {"vulnerabilities": []}
            else:
                raise Exception(f"Generic API returned status {response.status}")
    
    async def _fetch_from_web_scraper(self, source: Dict, query: str, max_results: int) -> Dict:
        """Fetch vulnerabilities from web scraper sources"""
        source_name = source["name"]
        
        if source_name == "SecurityFocus":
            return await self._scrape_securityfocus(query, max_results)
        elif source_name == "PacketStorm":
            return await self._scrape_packetstorm(query, max_results)
        elif source_name == "CVE-Details":
            return await self._scrape_cve_details(query, max_results)
        else:
            return {"vulnerabilities": []}
    
    async def _scrape_securityfocus(self, query: str, max_results: int) -> Dict:
        """Scrape SecurityFocus website"""
        url = f"https://www.securityfocus.com/bid?q={quote_plus(query)}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                if response.status == 200:
                    html = await response.text()
                    return await self._parse_securityfocus_html(html, max_results)
                else:
                    raise Exception(f"SecurityFocus returned status {response.status}")
    
    async def _parse_securityfocus_html(self, html: str, max_results: int) -> Dict:
        """Parse SecurityFocus HTML response"""
        soup = BeautifulSoup(html, 'html.parser')
        vulnerabilities = []
        
        # Find vulnerability entries
        vuln_entries = soup.find_all('tr', class_='vuln')
        
        for entry in vuln_entries[:max_results]:
            try:
                title_elem = entry.find('td', class_='title')
                if title_elem:
                    title = title_elem.get_text(strip=True)
                    link = title_elem.find('a')
                    url = f"https://www.securityfocus.com{link['href']}" if link else ""
                    
                    vulnerabilities.append({
                        "cve_id": None,
                        "description": title,
                        "severity": "unknown",
                        "source": "SecurityFocus",
                        "url": url
                    })
            except Exception as e:
                logger.warning(f"Error parsing SecurityFocus entry: {e}")
        
        return {"vulnerabilities": vulnerabilities}
    
    async def _scrape_packetstorm(self, query: str, max_results: int) -> Dict:
        """Scrape PacketStorm website"""
        url = f"https://packetstormsecurity.com/search/?q={quote_plus(query)}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                if response.status == 200:
                    html = await response.text()
                    return await self._parse_packetstorm_html(html, max_results)
                else:
                    raise Exception(f"PacketStorm returned status {response.status}")
    
    async def _parse_packetstorm_html(self, html: str, max_results: int) -> Dict:
        """Parse PacketStorm HTML response"""
        soup = BeautifulSoup(html, 'html.parser')
        vulnerabilities = []
        
        # Find exploit entries
        exploit_entries = soup.find_all('div', class_='exploit')
        
        for entry in exploit_entries[:max_results]:
            try:
                title_elem = entry.find('h2')
                if title_elem:
                    title = title_elem.get_text(strip=True)
                    link = title_elem.find('a')
                    url = f"https://packetstormsecurity.com{link['href']}" if link else ""
                    
                    vulnerabilities.append({
                        "cve_id": None,
                        "description": title,
                        "severity": "unknown",
                        "source": "PacketStorm",
                        "url": url
                    })
            except Exception as e:
                logger.warning(f"Error parsing PacketStorm entry: {e}")
        
        return {"vulnerabilities": vulnerabilities}
    
    async def _scrape_cve_details(self, query: str, max_results: int) -> Dict:
        """Scrape CVE Details website"""
        url = f"https://www.cvedetails.com/cve-details.php?t=1&cve_id={quote_plus(query)}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                if response.status == 200:
                    html = await response.text()
                    return await self._parse_cve_details_html(html, max_results)
                else:
                    raise Exception(f"CVE Details returned status {response.status}")
    
    async def _parse_cve_details_html(self, html: str, max_results: int) -> Dict:
        """Parse CVE Details HTML response"""
        soup = BeautifulSoup(html, 'html.parser')
        vulnerabilities = []
        
        # Find CVE entries
        cve_entries = soup.find_all('tr', class_='srrowns')
        
        for entry in cve_entries[:max_results]:
            try:
                cve_id_elem = entry.find('td', class_='cve_id')
                if cve_id_elem:
                    cve_id = cve_id_elem.get_text(strip=True)
                    link = cve_id_elem.find('a')
                    url = f"https://www.cvedetails.com{link['href']}" if link else ""
                    
                    vulnerabilities.append({
                        "cve_id": cve_id,
                        "description": entry.find('td', class_='cve_summary').get_text(strip=True) if entry.find('td', class_='cve_summary') else "",
                        "severity": "unknown",
                        "source": "CVE-Details",
                        "url": url
                    })
            except Exception as e:
                logger.warning(f"Error parsing CVE Details entry: {e}")
        
        return {"vulnerabilities": vulnerabilities}
    
    def get_cache_key(self, query: str, source: str) -> str:
        """Generate cache key for query and source"""
        return f"{source}:{query}"
    
    def is_cache_valid(self, cache_key: str) -> bool:
        """Check if cache entry is still valid"""
        if cache_key not in self.cache:
            return False
        
        cache_entry = self.cache[cache_key]
        cache_time = cache_entry.get("timestamp", 0)
        return (datetime.now().timestamp() - cache_time) < self.cache_duration
    
    def get_cached_result(self, cache_key: str) -> Optional[Dict]:
        """Get cached result if valid"""
        if self.is_cache_valid(cache_key):
            return self.cache[cache_key].get("data")
        return None
    
    def cache_result(self, cache_key: str, data: Dict):
        """Cache a result"""
        self.cache[cache_key] = {
            "data": data,
            "timestamp": datetime.now().timestamp()
        }
    
    def clear_cache(self):
        """Clear all cached results"""
        self.cache.clear()
    
    def get_cache_stats(self) -> Dict:
        """Get cache statistics"""
        return {
            "total_entries": len(self.cache),
            "cache_duration": self.cache_duration,
            "oldest_entry": min([entry["timestamp"] for entry in self.cache.values()]) if self.cache else None,
            "newest_entry": max([entry["timestamp"] for entry in self.cache.values()]) if self.cache else None
        } 